---
title: "Equation_exploration"
format: html
editor: visual
---

# *Parametres exploration*

-   *0 = species absence = the other species*
-   *1 = species presence*

***Eq: a + b\*X + c\*X^2^***

***Optimum : -b/(2c)***

***-b= opt \* 2 \* c***

-   *pas d'effet (plat) : -2 + 0 \* X + 0 \* X^2^*
-   *montée progressive : -2 + 3 \* X*
-   *monte fortement puis plateau : -2 + 20 \* X*
-   *cloche centrée : -2 + 15 \* X + -15 \* X^2^*
-   *cloche à droite (opt =0.7) : -2 + 15 \* X + -11 \* X^2^*

# Packages

```{r, , include = F, message=FALSE}
library(rstan)
rstan_options(auto_write = TRUE) # option pour ne pas recompiler à chaque fois !!! gain de temps
options(mc.cores = parallel::detectCores()) #option pour ajouter des coeurs au calcul
rstan_options(disable_march_warning = TRUE)
library(bayesplot) # visualiser la chaine de Markov
# library(shinystan) # for interactive stan output visualization
library(rstanarm) # for Bayesian automatic regression modelling using stan
library(brms) # Bayesian generalized multivariate non-linear multilevel models using stan
library(tidyverse)
```

```{r, eval=F}
n <- 7040 # abs + pres
X <- seq(0, 1, length.out = n) # env var
# Parameters
opt <- 0.07 # community median
a <- rstanarm::logit(0.5) # intercept ; logit(0.5)= 0) autant de 0 que de 1
# a <- rstanarm::logit(N1/(N1+N2))
b <- -50 
c <- ( -b/(opt*2))


# Compute presence probability
logit_p <- a + b * X + c * X^2 # equation
data <- data.frame(X = X, y = logit_p)
plot(data)

p <- 1 / (1 + exp(-logit_p))  # logistique transformation (inverse logit)

# Generate presence-absence data from probability
presence_absence <- rbinom(n, size = 1, prob = p) # Bernoulli = 1 trial

# data.frame of simulated data
data <- data.frame(X = X, Presence = presence_absence)

# Visualisation of simulated data
plot(X, presence_absence,
     main = "Simulated data : presence-absence vs explicative variable",
     xlab = "Explicative variable (X)", ylab = "Presence (1) / Absence (0)",
     pch = 19)
# proba
curve(1 / (1 + exp(-(a + b * x + c * x^2))), add = TRUE, col = "blue", lwd = 2)
```

# *Data simulation*

```{r}
dataParam <- data.frame(
  type = c("noeffect", "gentleslope", "bell", "rightbell", "convexbell", "negsigmoid", "possigmoid"),
  alpha=0) %>% 
  mutate(alpha= ifelse(type == "rightbell", -2, alpha)) %>% 
  mutate(beta1 = case_when(
    type == "noeffect" ~ 0,
    type == "gentleslope" ~ 3,
    type == "bell" ~ 15,
    type == "rightbell" ~ 15,
    type == "convexbell" ~ -15,
    type == "negsigmoid" ~ -15,
    type == "possigmoid" ~ 15) 
  ) %>% 
  mutate(beta2 = case_when(
    type == "noeffect" ~ 0,
    type == "gentleslope" ~ 0,
    type == "bell" ~ -15,
    type == "rightbell" ~ -11,
    type == "convexbell" ~ 15,
    type == "negsigmoid" ~ -15,
    type == "possigmoid" ~ 15) 
  )
dataParamL <- dataParam %>% pivot_longer(cols = c("alpha", "beta1", "beta2"),
                                         names_to = "Parameters",
                                         values_to = "Initial")
```

```{r}
n <- 500 # abs + pres
X <- seq(0, 1, length.out = n) # env var
# Parameters
a <- 0 # intercept ; logit(0.5)= 0) autant de 0 que de 1
b <- 0
c <- 0 # -b/(opt*2) 

data <- list(
  # data.frame of simulated data
  noeffect = data.frame(Environment = X,
                        # Generate presence-absence data from probability
                        Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                          # logistique transformation (inverse logit)
                                          prob = 1 / (1 + exp(-(a + b * X + c * X^2))))),
  
  gentleslope = data.frame(Environment = X,
                           # Generate presence-absence data from probability
                           Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                             # logistique transformation (inverse logit)
                                             prob = 1 / (1 + exp(-(a + 3 * X + c * X^2))))),
  
  bell = data.frame(Environment = X,
                    # Generate presence-absence data from probability
                    Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                      # logistique transformation (inverse logit)
                                      prob = 1 / (1 + exp(-(a + 15 * X + -15 * X^2))))), 
  
  rightbell = data.frame(Environment = X,
                         # Generate presence-absence data from probability
                         Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                           # logistique transformation (inverse logit)
                                           prob = 1 / (1 + exp(-(-2 + 15 * X + -11 * X^2))))), # opt =0.7
  
  convexbell = data.frame(Environment = X,
                          # Generate presence-absence data from probability
                          Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                            # logistique transformation (inverse logit)
                                            prob = 1 / (1 + exp(-(a + -15 * X + 15 * X^2))))), 
  
  negsigmoid = data.frame(Environment = X,
                          # Generate presence-absence data from probability
                          Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                            # logistique transformation (inverse logit)
                                            prob = 1 / (1 + exp(-(a + -15 * X + -15 * X^2))))), 
  
  possigmoid = data.frame(Environment = X,
                          # Generate presence-absence data from probability
                          Presence = rbinom(n, size = 1, # Bernoulli = 1 trial
                                            # logistique transformation (inverse logit)
                                            prob = 1 / (1 + exp(-(a + 15 * X + 15 * X^2))))) 
)

table(data[["noeffect"]]$Presence)
```

# Run models

```{r}
load("./Fits/ExploSimForm.Rdata")
behaviour <- "bell"
```

```{r Create a liste with data definitions as in the rstan file}
dataM <- lapply(data, function(x) list(N = nrow(x), #les noms des var doivent etre les memes que dans le fichier stan
                                       Presence = x$Presence,
                                       Environment = x$Environment))
```

```{r, eval=F}
# Model <- stan_model("Bernoulli_EnvOnly_quadratic.stan")
# for 1 dataset
fit <- stan(file= "Bernoulli_EnvOnly_quadratic.stan", data = dataM[[behaviour]], chains = 4, iter = 2000) # 0.511 seconds (Total)
fit
```

```{r, eval=F}
fits <- lapply(dataM, function(x) stan(file= "Bernoulli_EnvOnly_quadratic.stan", data = x, chains = 4, iter = 2000))
names(fits) <- names(dataM) # "noeffect" "gentleslope" "bell" "rightbell" "convexbell"  "negsigmoid" "possigmoid"
# fit

# posterior <- as.data.frame(fit, pars = c("alpha", "beta1", "beta2"))
# predictions <- as.data.frame(fit, pars = c("p", "lp__"))
fits[[behaviour]]
save(fits, file = "./Fits/ExploSimForm.Rdata")
```

# Compare initial vs estimated parameters values

```{r, posteriors table}
summaryfits <- lapply(names(fits), function(x) as.data.frame(summary(fits[[x]], 
                                                                     pars = c("alpha", "beta1", "beta2"))$summary[, c("50%", "2.5%", "97.5%")]) %>% 
                        tibble::rownames_to_column("Parameters")
)
names(summaryfits) <- names(fits)
summaryfits <- bind_rows(summaryfits, .id = "type")

summaryM <- dataParamL %>% 
  left_join(summaryfits, by = c("type", "Parameters")) %>% 
  mutate(Difference = round(`50%`-Initial,2))

summaryM
```

# Diagnostic plots

## Chains

```{r, eval= F, visualiser la progression des chaînes pour chaque paramètres}
mcmc_trace(as.array(fits[[behaviour]]), #as.array = comme vecteurs
           # facet_args=list(labeller=label_parsed), #pour mettre en lettre greques
           pars = c("alpha", "beta1", "beta2"),
           np = nuts_params(fits[[behaviour]]))

# rank histogram plots (Vehtarh et al., 2021)
mcmc_rank_hist(as.array(fits[[behaviour]]), pars = c("alpha", "beta1", "beta2"), ref_line = TRUE)

lapply(names(fits), function(x) mcmc_trace(as.array(fits[[x]]), #as.array = comme vecteurs
                                           # facet_args=list(labeller=label_parsed), #pour mettre en lettre greques
                                           pars = c("alpha", "beta1", "beta2"),
                                           np = nuts_params(fits[[x]])) # np pour afficher la divergeance
)
```

## Parameters correlation

```{r, eval=F, visualiser la relation entre chaque paramètre}
names(fits)
mcmc_pairs(as.array(fits[[behaviour]]), pars = c("alpha", "beta1", "beta2", "lp__", "o"))

#les paramètres doivent être indépendants et former une patate à leur valeur correspondant aux données.
lapply(names(fits), function(x) mcmc_pairs(as.array(fits[[x]]), pars = c("alpha", "beta1", "beta2")))
```

## Posteriors

```{r, vue 3D des posteriors}
mcmc_areas(as.array(fits[[1]]), prob=0.95, pars = c("alpha", "beta1", "beta2")) +
  labs(title=names(fits)[[1]])
mcmc_areas(as.array(fits[[behaviour]]), prob=0.95, pars = "o")
mcmc_areas(as.array(fits[["bell"]]), prob=0.95, pars = "o")
mcmc_areas(as.array(fits[["rightbell"]]), prob=0.95, pars = "o")
mcmc_areas(as.array(fits[["gentleslope"]]), prob=0.95, pars = "o")
mcmc_areas(as.array(fits[["negsigmoid"]]), prob=0.95, pars = "o")

p <- lapply(names(fits), function(x) mcmc_areas(as.array(fits[[x]]), prob=0.95, pars = c("alpha", "beta1", "beta2")) +
              labs(title=paste(x,"b= -4; c= -0.8")))

save(p, file = "./Plots/Posteriors_PA_1-10.Rdata")
```

```{r, vue 2D des posteriors}
lapply(names(fits), function(x) mcmc_intervals(as.array(fits[[x]]), prob=0.95, pars = c("alpha", "beta1", "beta2"))) # + # vu du dessus
# scale_x_continuous(limits = c(-15, 15), breaks = seq(-15,15, by=1)) 
```

# Predictions plots

## for 1 dataset

```{r, eval=F}
# Simulations mean
cbind(mu = apply(as.matrix(fits[[behaviour]], pars = "p"), 2, mean),# 2 for columns;  mean of all sim
      t(apply(as.matrix(fits[[behaviour]], pars = "p"), 2,
              quantile, probs = c(0.05, 0.95))),
      Opt = apply(as.matrix(fits[[behaviour]], pars = "o"), 2, mean)) %>% # optimum
  cbind(data[[behaviour]]) %>% 
  ggplot(aes(x = Environment)) +
  theme_minimal() +
  geom_point(aes(y = Presence, col = as.factor(Presence))) +
  geom_point(aes(y = mu), size=0.7) +
  geom_ribbon(aes(ymin = `5%`, ymax = `95%`), color = 'red', alpha = 0.2) + # 95% enveloppe
  geom_vline(aes(xintercept = Opt)) +
  stat_function(
    fun=function(x) 1 / (1 + exp(-(dataParam[dataParam$type==behaviour,]$alpha +
                                     dataParam[dataParam$type==behaviour,]$beta1 * x +
                                     dataParam[dataParam$type==behaviour,]$beta2 * x^2))),
    col = "blue", linewidth = 1) +
  
  labs(title = "Simulations mean", x ="Environment", y = "Presence probability", col= "Presence-absence")

# Simulations maximum likelihood  
mat <- as.data.frame(fits[[behaviour]], pars = c("p", "lp__")) %>% filter(`lp__`== max(`lp__`)) %>% select(-`lp__`)
op <- as.data.frame(fits[[behaviour]], pars = c("o", "lp__")) %>% filter(`lp__`== max(`lp__`)) %>% select(-`lp__`)

cbind(mu = unlist(as.vector(mat)),
      t(apply(as.matrix(fits[[behaviour]], pars = "p"), 2, 
              quantile, probs = c(0.05, 0.95))),
      Opt = unlist(as.vector(op)) # optimum
) %>% 
  cbind(data[[behaviour]]) %>% 
  ggplot(aes(x = Environment)) +
  theme_minimal() +
  geom_point(aes(y = Presence, col = as.factor(Presence))) +
  geom_point(aes(y = mu), size=0.7) +
  geom_ribbon(aes(ymin = `5%`, ymax = `95%`), color = 'red', alpha = 0.2) + # 95% enveloppe
  geom_vline(aes(xintercept = Opt)) +
  stat_function(
    fun=function(x) 1 / (1 + exp(-(dataParam[dataParam$type==behaviour,]$alpha +
                                     dataParam[dataParam$type==behaviour,]$beta1 * x +
                                     dataParam[dataParam$type==behaviour,]$beta2 * x^2))),
    col = "blue", linewidth = 1) +
  labs(title = "Simulations maximum likelihood", x ="Environment", y = "Presence probability", col= "Presence-absence")
```

## Facet

```{r}
# betas <- lapply(as.list(names(data)), function(type)
#   apply(as.matrix(fits[[type]], pars = c("beta1", "beta2")), 2, mean))
# names(betas) <- names(data)
# 
# opt <-  lapply(names(betas), function(x) -(betas[[x]]["beta1"]/(2*betas[[x]]["beta2"]))) # -beta1/2*beta2
# opt <- unlist(opt)
# names(opt) <- names(betas)
# opt <- as.data.frame(opt) %>%
#   tibble::rownames_to_column("type") %>% rename(Opt = opt)

lapply(as.list(names(data)), function(type)
  cbind(type = type, data[[type]],
        mu = apply(as.matrix(fits[[type]], pars = "p"), 2, median),
        t(apply(as.matrix(fits[[type]], pars = "p"), 2, 
                quantile, probs = c(0.05, 0.95))),
        Opt = apply(as.matrix(fits[[type]], pars = "o"), 2, median),
        Opt = t(apply(as.matrix(fits[[type]], pars = "o"), 2, 
                      quantile, probs = c(0.05, 0.95)))
  )) %>% 
  bind_rows() %>% 
  # left_join(opt, by="type") %>% 
  left_join(dataParam, by="type") %>%
  mutate(InitialProba = 1 / (1 + exp(-(alpha + beta1 * Environment + beta2 * Environment^2)))) %>% 
  mutate(InitialOpt = -beta1/(2*beta2)) %>% 
  ggplot(aes(x = Environment)) +
  # Presences
  geom_point(aes(y = Presence, col = as.factor(Presence))) +
  # Probas
  geom_point(aes(y = mu), size=0.7) +
  geom_ribbon(aes(ymin = `5%`, ymax = `95%`), color = 'red', alpha = 0.2) +
  # Optimum
  geom_vline(aes(xintercept = Opt)) +
  geom_vline(aes(xintercept = `Opt.5%`), linetype="dashed") +
  geom_vline(aes(xintercept = `Opt.95%`), linetype="dashed") +
    # Initial
  geom_line(aes(y = InitialProba), col = "blue", linewidth = 0.5) +
  geom_vline(aes(xintercept = InitialOpt), col = "blue", linewidth = 0.5) +
  labs(title = "Simulations median", y = "Presence probability", col= "Presence-absence") +
  facet_wrap(~ type, scales = "free", nrow = 1)

ggsave("ExploSimFormMedian.png", path = "D:/Mes Donnees/PhD/Figures/Modelisation", width = 35, height = 15, units = "cm", dpi=800, bg="white")


# betas <- lapply(as.list(names(data)), function(type)
#   unlist(as.vector(as.data.frame(fits[[type]], pars = c("beta1", "beta2", "lp__")) %>%
#                      filter(`lp__`== max(`lp__`)) %>% select(-`lp__`)))
# )
# names(betas) <- names(data)
# 
# opt <-  lapply(names(betas), function(x) -(betas[[x]]["beta1"]/(2*betas[[x]]["beta2"]))) # -beta1/2*beta2
# opt <- unlist(opt)
# names(opt) <- names(betas)
# opt <- as.data.frame(opt) %>% 
#   tibble::rownames_to_column("type") %>% rename(Opt = opt)

lapply(as.list(names(data)), function(type)
  cbind(type = type, data[[type]],
        mu = unlist(as.vector(as.data.frame(fits[[type]], pars = c("p", "lp__")) %>%
                                filter(`lp__`== max(`lp__`)) %>% select(-`lp__`))),
        t(apply(as.matrix(fits[[type]], pars = "p"), 2, 
                quantile, probs = c(0.05, 0.95))),
        Opt = unlist(as.vector(as.data.frame(fits[[type]], pars = c("o", "lp__")) %>%
                                 filter(`lp__`== max(`lp__`)) %>% select(-`lp__`))) 
  )) %>% 
  bind_rows() %>% 
  # left_join(opt, by="type") %>% 
  left_join(dataParam, by="type") %>%
  mutate(InitialProba = 1 / (1 + exp(-(alpha + beta1 * Environment + beta2 * Environment^2)))) %>% 
  mutate(InitialOpt = -beta1/(2*beta2)) %>% 
  ggplot(aes(x = Environment)) +
  geom_point(aes(y = Presence, col = as.factor(Presence))) +
  geom_point(aes(y = mu), size=0.7) +
  geom_ribbon(aes(ymin = `5%`, ymax = `95%`), color = 'red', alpha = 0.2) +
  geom_vline(aes(xintercept = Opt)) +
  geom_line(aes(y = InitialProba), col = "blue", linewidth = 1) +
  geom_vline(aes(xintercept = InitialOpt), col = "blue", linewidth = 0.5) +
  labs(title = "Simulations maximum likelihood", y = "Presence probability", col= "Presence-absence") +
  facet_wrap(~ type, scales = "free", nrow = 1)

ggsave("ExploSimFormMaxL.png", path = "D:/Mes Donnees/PhD/Figures/Modelisation", width = 35, height = 15, units = "cm", dpi=800, bg="white")
```

# *Only topo*

## *Linear*

```{r}

```

## *Quadratic*

```{r}

```

## Model comparaison

# Evaluation - Goodness of fit

https://campus.datacamp.com/courses/bayesian-regression-modeling-with-rstanarm/assessing-model-fit?ex=10

loo package which implements fast Pareto smoothed leave-one-out cross-validation (PSIS-LOO) (Vehtari, Gelman and Gabry, 2017) to compute expected log predictive density (elpd) PSIS : Pareto smoothed importance sampling the user needs to explicitly code the factors of the likelihood (actually, the terms of the log-likelihood) as a vector (see generated quantities in the stan file).

```{r}
# Fit the model with Stan
fit_1 <- stan("logistic.stan")
print(fit_1, "b")
# Compute LOO
log_lik_1 <- extract_log_lik(fit_1)
loo_1 <- loo(log_lik_1)
print(loo_1)
plot(loo_1)

# leave-one-out cross-validation
(loo1 <- loo(fit1, save_psis = TRUE))
# all Pareto k estimates have to be small (k< 0.5)
help('pareto-k-diagnostic') # for details.
#elpd_loo = the expected log pointwise predictive density
#p_loo = the effective number of parameters
#looic = the LOO information criterion 


# Widely Applicable or Watanabe-Akaike Information Criterion (WAIC; Watanabe 2010)
waic_1 <- waic(log_lik_1)
waic_2 <- waic(log_lik_2)
waic_diff <- compare(waic_1, waic_2)
print(waic_diff)

# Model comparaison
loo_diff <- loo_compare(loo1, loo2)
print(loo_diff)
```
